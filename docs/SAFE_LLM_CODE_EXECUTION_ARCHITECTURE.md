# Safe LLM Code Execution: Architecture & Best Practices

## Executive Summary

This document synthesizes current industry best practices for safely executing code generated by Large Language Models (LLMs). It covers security principles, technical approaches, specific tools/libraries, common pitfalls, and recommended architecture patterns for implementing safe code execution in production Django applications.

**Key Takeaway**: Pure Python sandboxing is fundamentally insecure. Production-grade solutions require OS-level isolation using containers, microVMs, or WebAssembly.

---

## Table of Contents

1. [Core Security Principles](#core-security-principles)
2. [Sandboxing Approaches](#sandboxing-approaches)
3. [Resource Limitations](#resource-limitations)
4. [Code Analysis and Validation](#code-analysis-and-validation)
5. [Permission Models](#permission-models)
6. [Monitoring and Logging](#monitoring-and-logging)
7. [Error Handling and Rollback](#error-handling-and-rollback)
8. [Security Considerations](#security-considerations)
9. [Production-Ready Tools and Frameworks](#production-ready-tools-and-frameworks)
10. [Architecture Patterns](#architecture-patterns)
11. [Common Pitfalls to Avoid](#common-pitfalls-to-avoid)
12. [Implementation Recommendations for Django](#implementation-recommendations-for-django)

---

## Core Security Principles

### 1. **Defense in Depth**

Multiple layers of security controls work together to protect the host system. An [LLM sandbox embodies a security philosophy](https://www.sandgarden.com/learn/llm-sandbox) recognizing the inherent unpredictability of AI-generated content, as language models create code without full awareness of security implications.

**Key layers:**
- OS-level isolation (containers, VMs, WebAssembly)
- System call filtering (seccomp)
- Mandatory access control (AppArmor, SELinux)
- Resource limits (CPU, memory, time)
- Network restrictions
- Filesystem isolation
- Code analysis before execution

### 2. **Least Privilege**

[Microsoft recommends](https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/generative-ai/mlops-in-openai/security/security-plan-llm-application) enforcing least privilege control on LLM access to backend systems. [WebAssembly-based sandboxes](https://www.sandgarden.com/learn/llm-sandbox) can be configured to provide exactly the capabilities needed for specific AI tasks while denying access to everything else.

**Implementation:**
- Grant minimal system permissions
- Capability-based security models
- Per-execution token scoping
- Isolated execution environments
- No direct host kernel access

### 3. **Zero Trust for LLM Output**

Treat LLM-generated code as untrusted input. The [OWASP Top 10 for LLMs](https://owasp.org/www-project-top-10-for-large-language-model-applications/) emphasizes that [neglecting to validate LLM outputs](https://www.tigera.io/learn/guides/llm-security/owasp-top-10-llm/) may lead to downstream security exploits, including code execution that compromises systems and exposes data.

**Best practices:**
- Never execute generated code without sandboxing
- Validate and sanitize all outputs
- Implement input validation on LLM responses
- Use separate secured environments for code execution

### 4. **Ephemeral Execution Environments**

[After code runs, the process and its sandbox should be destroyed](https://www.sandgarden.com/learn/llm-sandbox), significantly reducing the time attackers have to break out.

**Benefits:**
- Limits attack time window
- Prevents state persistence between executions
- Reduces blast radius of compromise
- Simplifies cleanup and resource management

---

## Sandboxing Approaches

### 1. Container-Based Sandboxing

**Overview:**
[Container-based sandboxes](https://www.sandgarden.com/learn/llm-sandbox) provide a lightweight yet effective barrier between AI operations and the host system, allowing code to run with necessary resources while preventing unauthorized access to sensitive system components.

**Technologies:**

#### Standard Docker Containers
- **Pros**: Standard tooling, no performance penalty
- **Cons**: Shared kernel with host, weaker isolation
- **Use case**: Low-risk workloads, development environments

#### gVisor
[gVisor](https://gvisor.dev/) is an open source virtual machine monitor (VMM) that provides an extra layer of security by implementing the Linux kernel in a memory-safe language (Go).

**How it works:**
- Intercepts all sandboxed application system calls
- Implements most kernel primitives in user space
- [Implements ~70% of 319 Linux syscalls](https://medium.com/geekculture/container-sandboxing-gvisor-b191dafdc8a2) for sandboxed apps
- Uses only ~20 syscalls to communicate with host kernel

**Security features:**
- [Minimal device model](https://github.com/firecracker-microvm/firecracker) (network, block I/O, timer, clock, serial, keyboard)
- Process jailing using cgroups and seccomp BPF
- Integration with Docker and Kubernetes via runsc runtime
- [Protects host from applications](https://gvisor.dev/) by intercepting system calls

**Production use:**
- Used by [E2B](https://e2b.dev/) for LLM agent sandboxing
- Powers many serverless platforms
- Suitable for multi-tenant environments

### 2. MicroVM-Based Sandboxing

#### Firecracker
[Firecracker](https://firecracker-microvm.github.io/) is a lightweight virtualization technology that powers [AWS Lambda](https://aws.amazon.com/blogs/aws/firecracker-lightweight-virtualization-for-serverless-computing/) and AWS Fargate.

**Key characteristics:**
- Starts user code in as little as **125ms**
- Supports **150 microVMs per second per host**
- **<5 MiB memory overhead** per microVM
- Uses Linux KVM (Kernel-based Virtual Machine)

**Security model:**
- [Hardware virtualization provides strong isolation](https://www.anthony-balitrand.fr/2025/08/12/firecracker-microvms-the-power-behind-aws-lambda/)
- Guest kernel itself is treated as untrusted
- Minimal attack surface through limited device model
- Process jailed with cgroups and seccomp BPF
- Companion "jailer" program provides second line of defense

**AWS Lambda architecture:**
[Lambda uses Firecracker](https://www.anthony-balitrand.fr/2025/08/12/firecracker-microvms-the-power-behind-aws-lambda/) to allow full guest kernel access while isolating the guest kernel from the host through hardware virtualization, preventing untrusted code from directly calling host kernel.

**Use cases:**
- Multi-tenant serverless platforms
- High-density workload isolation
- Security-critical applications
- Production LLM code execution

### 3. WebAssembly (WASM) Sandboxing

[WebAssembly modules execute within a sandboxed environment](https://webassembly.org/docs/security/) separated from the host runtime using fault isolation techniques.

**Security features:**
- **Memory isolation**: [Bounds-checked linear memory](https://webassembly.org/docs/security/), isolated from runtime, zeroed by default
- **Control flow integrity**: Protected call stacks prevent code injection
- **No ROP attacks**: [Control-flow integrity ensures valid call targets](https://webassembly.org/docs/security/)
- **Sandboxed by design**: Must import all functionality
- **Deny-by-default capabilities**

**Wasmtime Runtime:**
[Wasmtime](https://docs.wasmtime.dev/security.html) is one of WebAssembly's main implementations for executing untrusted code safely inside sandboxes.

**Capabilities:**
- WASI APIs for filesystem access (capability-based security)
- Applications only access explicitly granted files/directories
- [Mechanically verified security properties](https://ieeexplore.ieee.org/document/10179357/) (WaVe project)
- [Provably-safe multilingual sandboxing](https://www.usenix.org/conference/usenixsecurity22/presentation/bosamiya)

**Limitations:**
- [Doesn't inherently guarantee security](https://snyk.io/blog/webassembly-security-concerns/) - developers must secure code and lock down dependencies
- Limited language ecosystem compared to containers
- Performance overhead for some workloads

**Use cases:**
- [Sandboxing agentic AI workflows](https://developer.nvidia.com/blog/sandboxing-agentic-ai-workflows-with-webassembly/)
- Browser-based code execution
- Embedded systems
- Edge computing

### 4. OS-Level Security Mechanisms

#### Seccomp (Secure Computing Mode)
[Seccomp](https://en.wikipedia.org/wiki/Seccomp) allows a process to make a one-way transition into a "secure" state where it can only use exit(), sigreturn(), read(), and write() to already-open file descriptors.

**Implementation:**
- [Restricts which system calls a process can invoke](https://medium.com/@rifewang/kubernetes-seccomp-apparmor-selinux-pod-security-standards-and-admission-control-c2d9b7c56031)
- [Docker's default profile disables 44 system calls](https://medium.com/@mughal.asim/understanding-seccomp-and-how-it-compares-to-apparmor-for-container-security-5317b3e9b1d6)
- Prevents mount, reboot, setns, and other dangerous operations

#### AppArmor
[AppArmor uses profiles](https://securitylabs.datadoghq.com/articles/container-security-fundamentals-part-5/) to determine what files and permissions an application requires.

**Features:**
- Path-based mandatory access control
- Restricts files, network traffic, Linux capabilities
- Used by [CodeJail](https://github.com/openedx/codejail) for secure Python execution
- Profile-based process restriction

#### SELinux
[SELinux labels Linux resources](https://securitylabs.datadoghq.com/articles/container-security-fundamentals-part-5/) and restricts access based on labels and process properties.

**Characteristics:**
- Label-based access control
- Fine-grained security policies
- Unless policy defined, no access granted
- More complex than AppArmor but more powerful

**Comparison:**
- [Seccomp](https://www.starlab.io/blog/linux-security-modules-lsms-vs-secure-computing-mode-seccomp): Limits system calls
- [AppArmor](https://security.stackexchange.com/questions/196881/docker-when-to-use-apparmor-vs-seccomp-vs-cap-drop): Controls resource access
- [SELinux](https://security.stackexchange.com/questions/196881/docker-when-to-use-apparmor-vs-seccomp-vs-cap-drop): Policy-based access control
- **Best practice**: Use all three together for defense in depth

---

## Resource Limitations

### 1. Python's `resource` Module (Unix/Linux)

[Python's resource module](https://luminousmen.com/post/python-resource-limitation/) makes resource limitation straightforward.

**CPU Time Limits:**
```python
import resource

# Limit CPU time to 5 seconds
resource.setrlimit(resource.RLIMIT_CPU, (5, 5))
```

[When this limit is exceeded](https://www.geeksforgeeks.org/python/python-how-to-put-limits-on-memory-and-cpu-usage/), a SIGXCPU signal is sent to the process.

**Memory Limits:**
```python
# Limit virtual memory to 512 MB
resource.setrlimit(resource.RLIMIT_AS, (512 * 1024 * 1024, 512 * 1024 * 1024))
```

[When no more memory is available](https://discuss.python.org/t/limiting-the-memory-usage-of-the-process/34865), the program generates MemoryError exceptions instead of affecting the entire process.

**Available limits:**
- `RLIMIT_CPU`: CPU time in seconds
- `RLIMIT_AS`: Virtual memory (address space)
- `RLIMIT_NOFILE`: Number of open file descriptors
- `RLIMIT_STACK`: Program stack size

**Limitations:**
- [Only works on Unix systems](https://docs.python.org/3/library/resource.html)
- May not work on all Unix variants
- Can be bypassed in some configurations

### 2. Container-Based Limits

**Docker resource constraints:**
```bash
docker run --cpus=0.5 --memory=512m --memory-swap=512m \
  --pids-limit=100 --network=none my-sandbox
```

**Kubernetes resource limits:**
```yaml
resources:
  limits:
    cpu: "500m"
    memory: "512Mi"
  requests:
    cpu: "250m"
    memory: "256Mi"
```

### 3. Recommended Limits for LLM Code Execution

Based on [industry best practices](https://www.moveworks.com/us/en/resources/blog/secure-code-execution-for-llms):

**Execution constraints:**
- **Operations**: Maximum 8,192 operations before termination
- **Time**: 8.2 seconds maximum execution time
- **Memory**: Size limits on numerical classes and strings
- **Builtins**: Reduced or custom builtin functions

**Network restrictions:**
- No network access by default
- Whitelist specific domains if needed
- Monitor all network traffic

**Filesystem restrictions:**
- Read-only root filesystem
- Limit writable temp directories
- No access to sensitive paths

---

## Code Analysis and Validation

### 1. Abstract Syntax Tree (AST) Analysis

[The AST module in Python](https://twosixtech.com/blog/hijacking-the-ast-to-safely-handle-untrusted-python/) can safely take code from untrusted user input by parsing and validating before execution.

**Safe parsing:**
```python
import ast

# Parse code without executing
tree = ast.parse(code, mode='eval')  # 'eval' is more restricted than 'exec'

# Validate AST for dangerous operations
# Never call eval() or exec() directly on user input
```

**SAST Tools:**
[SAST tools preprocess code](https://dl.acm.org/doi/10.1007/s11265-022-01740-z) into Abstract Syntax Trees and perform security analysis by studying context and data flow relationships.

#### Bandit
[Bandit](https://github.com/PyCQA/bandit) processes each file, builds an AST, and runs security plugins against the nodes.

**Features:**
- Finds common security issues in Python code
- Identifies dangerous function calls
- Detects unsafe imports and practices

**Example dangerous patterns:**
- `MySQLCursor.execute()` with unsanitized data
- Python's `eval()` builtin
- Unsafe deserialization
- Hardcoded credentials

### 2. Data Flow Analysis

[Data flow analysis tracks](https://bito.ai/blog/python-sast-tools/) the lifecycle of data from untrusted inputs to where it is used, verifying dangerous inputs don't flow unchecked into sensitive functions.

**Key concepts:**
- Track user input sources
- Identify sensitive sinks (exec, eval, subprocess, database queries)
- Verify sanitization between source and sink
- Flag unvalidated data flows

### 3. Whitelisting Approach

[Good security for exposed applications](https://twosixtech.com/blog/hijacking-the-ast-to-safely-handle-untrusted-python/) includes a whitelist - a restricted list of actions the user can do.

**Implementation:**
- Parse AST to extract all operations
- Check against allowed operations whitelist
- Reject code using disallowed features
- Block dangerous imports and builtins

---

## Permission Models

### 1. Capability-Based Security

[Capability-based security models](https://www.sandgarden.com/learn/llm-sandbox) provide exactly the capabilities needed for specific AI tasks while denying access to everything else, aligning with least privilege.

**Principles:**
- No ambient authority
- Explicit capability grants
- Unforgeable capability tokens
- Revocable permissions

**WebAssembly WASI example:**
[Wasmtime implements WASI APIs](https://docs.wasmtime.dev/security.html) with capability-based security for filesystem access, ensuring applications only access explicitly granted files and directories.

### 2. Programmable Policy Frameworks

[Progent](https://arxiv.org/html/2504.11703) provides a programmable framework to define and enforce precise security policies for privilege control in LLM agents.

**Features:**
- Fully programmable security constraints
- Fine-grained controls down to individual tool call arguments
- Per-user-query policy generation
- Minimal permissions for each task

### 3. External Authorization

[Authorization decision-making should occur external to the LLM](https://www.cmdzero.io/blog-posts/securing-llm-backed-systems-a-guide-to-csas-authorization-best-practices) to guarantee consistent application of security policies.

**Best practices:**
- Centralized policy enforcement
- Separate from LLM logic
- Apply least privilege and need-to-know
- Minimize potential breach damage

---

## Monitoring and Logging

### 1. What to Log

[Audit logging tools should capture](https://www.zengrc.com/blog/audit-log-best-practices-for-information-security/):

**Essential events:**
- All system and user activity
- Access control changes
- System events
- Data access and modification
- Administrative actions (create/delete users, permission changes)
- Code execution requests and results

**Log components:**
- **Who**: User or process identifier
- **What**: Specific action taken
- **When**: Timestamp of event
- **Where**: Source IP, location, component
- **Outcome**: Success, failure, error details

### 2. Real-Time Monitoring

[Audit logging tools should monitor logs in real time](https://www.datadoghq.com/knowledge-center/audit-logging/) and provide alerts when suspicious or unauthorized activity is detected.

**Implementation:**
- Automated log analysis
- Anomaly detection
- Alert generation for security events
- Dashboard visualization

**High-risk applications:**
[Information should be analyzed on a regular basis](https://www.computerweekly.com/tip/Best-practices-for-audit-log-review-for-IT-security-investigations); for high-risk applications, this could mean automated reviews on an hourly basis.

### 3. Security Tools

[Setup security tools](https://sematext.com/blog/best-practices-for-efficient-log-management-and-monitoring/) such as auditd or OSSEC agents that implement real-time log analysis and generate alert logs pointing to potential security issues.

### 4. Log Storage and Retention

**Immutability:**
[Audit logs aim to be immutable](https://middleware.io/blog/audit-logs/) so that no user or service can alter audit trails.

**Retention:**
[Logs should be kept for a minimum of one year](https://www.digitalguardian.com/blog/audit-log-best-practices-security-compliance), in case they are needed for investigation.

**Search capabilities:**
[Tools need advanced searching capabilities](https://www.strongdm.com/blog/audit-log-review-management), including searching by key fields and indicators, and running reports from specified timeframes.

### 5. Data Sensitivity

[Avoid logging highly sensitive data](https://sematext.com/blog/best-practices-for-efficient-log-management-and-monitoring/), such as credit card numbers, unless logging and storage processes meet security requirements for that data.

### 6. Compliance

[Ensure audit logging tools meet applicable compliance requirements](https://www.zengrc.com/blog/audit-log-best-practices-for-information-security/), including HIPAA, PCI DSS, and GDPR.

---

## Error Handling and Rollback

### 1. Production Error Handling

[Production LLM applications face unique challenges](https://markaicode.com/llm-error-handling-production-guide/) from API failures, rate limits, and unpredictable responses, requiring proven error handling strategies.

**Key principles:**
- Graceful degradation
- Maintain core functionality during LLM service failures
- Clear error messages for users
- Automated recovery mechanisms

### 2. Transaction Safety

**Database transactions:**
[In Postgres, the vast majority of DML and DDL commands](https://stackoverflow.com/questions/76056890/is-there-anything-one-cannot-do-and-then-rollback-safely-in-transaction) are fully transactional and their effects can be rolled back.

**Best practices:**
- Wrap code execution in transactions where possible
- Enable rollback of database changes on failure
- Avoid accidental commits during execution
- Use savepoints for nested operations

### 3. Prompt Rollback

[Prompt rollback](https://latitude-blog.ghost.io/blog/prompt-rollback-in-production-systems/) ensures reliable and stable performance in production systems using LLMs, allowing teams to quickly revert to previous prompt versions.

**Benefits:**
- Quick recovery from bad outputs
- Performance regression protection
- Version control for prompts
- A/B testing capabilities

### 4. Sandbox Cleanup

**Post-execution:**
- Destroy execution environment completely
- Clean up temporary files and resources
- Reset state for next execution
- Garbage collect unused resources

---

## Security Considerations

### 1. OWASP Top 10 for LLM Applications

#### LLM01: Improper Output Handling
[Neglecting to validate LLM outputs](https://owasp.org/www-project-top-10-for-large-language-model-applications/) may lead to downstream security exploits, including code execution that compromises systems and exposes data.

**Mitigations:**
- Treat LLM as any other user (zero trust)
- Apply input validation to responses
- Follow [OWASP ASVS](https://owasp.org/www-project-application-security-verification-standard/) guidelines
- Escape/strip HTML
- Block dangerous protocols
- Parameterize queries
- **Never execute generated code without sandbox**

#### LLM07: Insecure Plugins and Tools
[LLM plugins processing untrusted inputs](https://www.tigera.io/learn/guides/llm-security/owasp-top-10-llm/) and having insufficient access control risk severe exploits like remote code execution.

**Mitigations:**
- Proper input validation in plugins
- Implement access controls
- Handle data securely
- Isolate plugin execution
- Monitor runtime behavior

#### LLM08: Excessive Agency
[Granting LLMs unchecked autonomy](https://www.mend.io/blog/2025-owasp-top-10-for-llm-applications-a-quick-guide/) to take action can lead to unintended consequences.

**Mitigations:**
- Limit LLM functionality and permissions
- Human-in-the-loop for critical actions
- Rate limiting on operations
- Audit all autonomous actions

### 2. Common Attack Vectors

#### Sandbox Escape
[Judge0 had a sandbox escape vulnerability](https://tantosec.com/blog/judge0/) (CVE-2024-29021) demonstrating the difficulty of secure sandboxed code execution.

**Defenses:**
- Multiple isolation layers
- Regular security audits
- Keep sandbox software updated
- Monitor escape attempts

#### Injection Attacks
**Types:**
- Command injection
- SQL injection
- Path traversal
- Template injection

**Mitigations:**
- Input sanitization
- Parameterized queries
- Whitelist validation
- Context-aware escaping

#### Privilege Escalation
**Risks:**
- Exploiting SUID binaries
- Kernel vulnerabilities
- Container breakout
- Capability abuse

**Defenses:**
- Remove unnecessary binaries
- Regular patching
- Capability dropping
- User namespace isolation

### 3. Network Security

**Isolation levels:**
1. **No network access** (most secure)
2. **Whitelist specific domains**
3. **Egress filtering only**
4. **Full network with monitoring**

**Best practice:**
Start with no network access and add permissions only as needed.

---

## Production-Ready Tools and Frameworks

### 1. E2B (Enterprise Grade)

[E2B](https://e2b.dev/) is an open-source infrastructure for running AI-generated code in secure isolated sandboxes in the cloud.

**Key features:**
- [Sandbox startup <200ms](https://e2b.dev/docs) (same region as client)
- Up to 24-hour sandbox lifetime
- [Powered by Firecracker microVMs](https://e2b.dev/docs)
- [Used by 88% of Fortune 100 companies](https://github.com/e2b-dev/E2B)
- [~50% of Fortune 500 usage](https://github.com/e2b-dev/E2B)
- Millions of sandboxes per week

**Deployment options:**
- Your AWS, GCP, or Azure account
- Your VPC
- E2B's cloud infrastructure

**SDKs:**
- Python SDK
- JavaScript SDK
- LLM-agnostic (works with any model)

**Integrations:**
- LangChain
- LlamaIndex
- Other AI frameworks

**Use cases:**
- AI data analysis/visualization
- Running AI-generated code (any language)
- Coding agent playgrounds
- Codegen evaluations
- Full AI-generated apps

### 2. CodeJail

[CodeJail](https://github.com/openedx/codejail) manages execution of untrusted code in secure sandboxes using AppArmor.

**Architecture:**
- Primarily for Python (supports other languages)
- [Security enforced with AppArmor](https://github.com/openedx/codejail)
- Requires two user accounts (main + sandbox)
- [Not secure by default](https://github.com/openedx/codejail/blob/master/README.rst) - requires proper configuration

**Resource limits:**
- [Uses Linux rlimit mechanisms](https://github.com/openedx/codejail/blob/master/README.rst)
- CPU time restrictions
- Memory constraints
- Process limits

**Limitations:**
- Configuration complexity
- If misconfigured, runs code insecurely
- Linux-only
- Requires AppArmor setup

**Best for:**
- Educational platforms (used by Open edX)
- Python-focused applications
- Existing AppArmor infrastructure

### 3. Piston

[Piston](https://github.com/engineer-man/piston) is a high-performance general-purpose code execution engine.

**Architecture:**
- Node.js API within container
- [Writes source code and executes in Isolate sandbox](https://github.com/engineer-man/piston)
- Multi-language support

**Features:**
- Fast execution
- Multiple language runtimes
- API-based interface

**Best for:**
- Code evaluation platforms
- Online IDEs
- Multi-language support needs

### 4. Judge0

[Judge0](https://judge0.com/) is a robust, scalable, and open-source online code execution system.

**Capabilities:**
- [Build competitive programming platforms](https://github.com/judge0/judge0)
- E-learning platforms
- Candidate assessment
- Online code editors
- Online IDEs

**Features:**
- Single-file and multi-file program support
- Resource limitations
- Many programming languages
- Predefined compilation/execution scripts

**Security note:**
[CVE-2024-29021 sandbox escape](https://tantosec.com/blog/judge0/) discovered - demonstrates need for ongoing security maintenance.

**Best for:**
- Educational platforms
- Coding challenges
- Assessment tools

### 5. RestrictedPython

[RestrictedPython](https://restrictedpython.readthedocs.io/en/latest/) is NOT a sandbox system but helps define a trusted environment.

**What it does:**
- [Transforms Python code to control names, modules, and objects](https://pypi.org/project/RestrictedPython/)
- Originated from Zope (~2000)
- CPython 3.9-3.13 support
- [Does NOT support PyPy](https://restrictedpython.readthedocs.io/en/latest/)

**Limitations:**
[Too many ways to escape](https://stackoverflow.com/questions/3068139/how-can-i-sandbox-python-in-pure-python) using Python's introspection features. **Should NOT be used alone for security.**

**Best for:**
- Additional layer in multi-layer defense
- Template engines
- Configuration scripts
- Non-security-critical restrictions

### 6. PyPy Sandbox

[PyPy has support for creating a sandboxed Python interpreter](https://wiki.python.org/moin/SandboxedPython) that serializes all I/O for inspection.

**Architecture:**
- Runs arbitrary Python code
- Special environment serializes I/O
- Check and decide allowed commands
- Before actually running them

**Limitations:**
- Separate Python implementation (not CPython)
- Limited ecosystem compatibility
- Performance characteristics differ from CPython

---

## Architecture Patterns

### 1. Synchronous Execution (Simple Use Cases)

```
Client Request → API Gateway → Sandbox → Response
```

**Characteristics:**
- Direct request-response
- Client waits for completion
- Simple error handling
- Limited execution time

**Best for:**
- Quick computations (<5 seconds)
- Interactive REPL environments
- Simple code validation

### 2. Asynchronous Queue-Based (Production)

```
Client Request → Queue → Worker Pool → Results Store → Webhook/Polling
```

**Characteristics:**
- Decoupled execution
- Scalable worker pool
- Long-running tasks
- Retry mechanisms
- Result persistence

**Best for:**
- Batch processing
- Long-running computations
- High-volume workloads
- Production systems

### 3. Multi-Tenant Isolation

```
Tenant A → Dedicated Namespace → Firecracker microVM
Tenant B → Dedicated Namespace → Firecracker microVM
Tenant C → Dedicated Namespace → Firecracker microVM
```

**Security layers:**
- Per-tenant namespaces
- Isolated microVMs
- Separate resource quotas
- Network segmentation
- Dedicated secrets

**Best for:**
- SaaS platforms
- Multi-customer environments
- Compliance requirements

### 4. Lambda/Serverless Pattern

```
API Request → Lambda Function → Firecracker microVM → Response
```

**Characteristics:**
- [AWS Lambda architecture](https://aws.amazon.com/blogs/aws/firecracker-lightweight-virtualization-for-serverless-computing/)
- Automatic scaling
- Pay-per-execution
- Built-in monitoring
- Managed infrastructure

**Best for:**
- Variable workloads
- Cost optimization
- Minimal operations overhead

### 5. Layered Defense Architecture

```
┌─────────────────────────────────────┐
│   Application Layer                 │
│   - Input validation                │
│   - AST analysis                    │
│   - Whitelist checking              │
└────────────┬────────────────────────┘
             │
┌────────────▼────────────────────────┐
│   Container Layer (gVisor/Docker)   │
│   - Process isolation               │
│   - Resource limits                 │
│   - Network restrictions            │
└────────────┬────────────────────────┘
             │
┌────────────▼────────────────────────┐
│   OS Security Layer                 │
│   - Seccomp (syscall filtering)    │
│   - AppArmor/SELinux (MAC)         │
│   - Capabilities                    │
└────────────┬────────────────────────┘
             │
┌────────────▼────────────────────────┐
│   Hardware/Hypervisor Layer         │
│   - Firecracker microVM             │
│   - KVM hardware isolation          │
└─────────────────────────────────────┘
```

**Best for:**
- Maximum security requirements
- Untrusted code execution
- Production LLM applications

---

## Common Pitfalls to Avoid

### 1. **Pure Python Sandboxing**

**Problem:**
[The consensus among security experts](https://softwareengineering.stackexchange.com/questions/191623/best-practices-for-execution-of-untrusted-code) is that putting a sandbox in CPython is the wrong design, as there are too many ways to escape using introspection.

**Why it fails:**
[Python is inherently introspectable at multiple levels](https://checkmarx.com/zero-post/glass-sandbox-complexity-of-python-sandboxing/). Every object maintains references to other objects through attributes and methods, creating alternative pathways to data access.

**Examples:**
```python
# Escape via type introspection
type(f)  # Get access to "file" class itself

# Escape via object hierarchy
object.__subclasses__()  # Access all classes

# Import via introspection
__import__('os').system('whoami')
```

**Solution:**
[The best practice is to segregate untrusted code via a system sandbox](https://wiki.python.org/moin/SandboxedPython), such as a container with only Python and dependencies.

### 2. **Relying on Audit Hooks for Security**

**Problem:**
[Audit hooks are not suitable for implementing a sandbox](https://healeycodes.com/running-untrusted-python-code), as malicious code can trivially disable or bypass hooks.

**Solution:**
Use audit hooks for monitoring only, not security enforcement.

### 3. **Insufficient Resource Limits**

**Problems:**
- Fork bombs
- Memory exhaustion
- Infinite loops
- CPU monopolization

**Solution:**
Always implement ALL resource limits:
- CPU time
- Memory (virtual and physical)
- Process count
- File descriptor limits
- Disk I/O
- Network bandwidth

### 4. **Trusting LLM Output Without Validation**

**Problem:**
[OWASP identifies improper output handling](https://owasp.org/www-project-top-10-for-large-language-model-applications/) as a critical vulnerability - code execution, XSS, and data exposure.

**Solution:**
- Validate all LLM outputs
- Sanitize before execution
- Use whitelisting
- Never trust LLM-generated code

### 5. **Persistent State Between Executions**

**Problem:**
- State leakage between users
- Pollution of execution environment
- Accumulation of files/processes

**Solution:**
[Destroy the process and sandbox after code runs](https://www.sandgarden.com/learn/llm-sandbox), limiting attack time window.

### 6. **Overly Permissive Network Access**

**Problem:**
- Data exfiltration
- Command-and-control communication
- Lateral movement
- DDoS participation

**Solution:**
- Default to no network access
- Whitelist specific endpoints only
- Monitor all network traffic
- Use egress filtering

### 7. **Insufficient Logging**

**Problem:**
- Can't detect attacks
- No audit trail
- Can't debug failures
- Compliance violations

**Solution:**
- Log all execution requests
- Capture all output and errors
- Record resource usage
- Alert on anomalies

### 8. **Single Layer of Defense**

**Problem:**
Any single security mechanism can be bypassed.

**Solution:**
[Implement defense in depth](https://www.sandgarden.com/learn/llm-sandbox) with multiple security layers.

### 9. **Outdated Dependencies**

**Problem:**
[Judge0 CVE-2024-29021](https://tantosec.com/blog/judge0/) demonstrates vulnerabilities in sandbox software.

**Solution:**
- Regular security updates
- Dependency scanning
- Vulnerability monitoring
- Patch management process

### 10. **Ignoring Compliance Requirements**

**Problem:**
- GDPR violations
- PCI DSS non-compliance
- HIPAA violations
- SOC 2 failures

**Solution:**
[Ensure audit logging meets applicable compliance](https://www.zengrc.com/blog/audit-log-best-practices-for-information-security/): HIPAA, PCI DSS, GDPR.

---

## Implementation Recommendations for Django

### 1. **Architecture Decision**

For a production Django application, choose based on scale:

#### Small Scale (< 100 executions/day)
- **Use E2B** with Python SDK
- Leverage their managed infrastructure
- Minimal operational overhead
- Built-in security best practices

#### Medium Scale (100-10,000 executions/day)
- **Self-hosted with gVisor**
- Docker containers with runsc runtime
- Django task queue (Celery)
- PostgreSQL for result storage

#### Large Scale (> 10,000 executions/day)
- **Firecracker microVMs**
- Kubernetes with dedicated node pools
- Horizontal autoscaling
- Distributed task processing

### 2. **Django Integration Pattern**

```python
# apps/ai/services/code_executor.py
from typing import Dict, Any
import uuid
from django.conf import settings
from .sandbox_client import SandboxClient

class CodeExecutor:
    """Executes LLM-generated code safely."""

    def __init__(self):
        self.sandbox = SandboxClient(
            api_key=settings.SANDBOX_API_KEY,
            timeout=settings.CODE_EXECUTION_TIMEOUT
        )

    def execute(
        self,
        code: str,
        language: str = 'python',
        user_id: int = None
    ) -> Dict[str, Any]:
        """
        Execute code in isolated sandbox.

        Returns:
            {
                'success': bool,
                'output': str,
                'error': str,
                'execution_time': float,
                'execution_id': str
            }
        """
        execution_id = str(uuid.uuid4())

        # 1. Validate code before execution
        if not self._validate_code(code, language):
            return {
                'success': False,
                'error': 'Code validation failed',
                'execution_id': execution_id
            }

        # 2. Log execution attempt
        self._log_execution(
            execution_id=execution_id,
            code=code,
            user_id=user_id
        )

        try:
            # 3. Execute in sandbox
            result = self.sandbox.execute(
                code=code,
                language=language,
                timeout=settings.CODE_EXECUTION_TIMEOUT,
                memory_limit=settings.CODE_MEMORY_LIMIT,
                cpu_limit=settings.CODE_CPU_LIMIT
            )

            # 4. Log result
            self._log_result(execution_id, result)

            return {
                'success': True,
                'output': result.get('output'),
                'execution_time': result.get('time'),
                'execution_id': execution_id
            }

        except Exception as e:
            # 5. Log error
            self._log_error(execution_id, str(e))

            return {
                'success': False,
                'error': str(e),
                'execution_id': execution_id
            }

    def _validate_code(self, code: str, language: str) -> bool:
        """AST-based validation and whitelist checking."""
        if language == 'python':
            return self._validate_python(code)
        return True

    def _validate_python(self, code: str) -> bool:
        """Validate Python code using AST analysis."""
        import ast
        try:
            tree = ast.parse(code, mode='exec')
            # Check for dangerous operations
            # Return False if found
            return True
        except SyntaxError:
            return False
```

### 3. **Celery Task Integration**

```python
# apps/ai/tasks.py
from celery import shared_task
from .services.code_executor import CodeExecutor

@shared_task(
    bind=True,
    max_retries=3,
    time_limit=60,
    soft_time_limit=50
)
def execute_code_async(self, code: str, language: str, user_id: int):
    """
    Asynchronous code execution task.
    """
    executor = CodeExecutor()

    try:
        result = executor.execute(
            code=code,
            language=language,
            user_id=user_id
        )
        return result

    except Exception as exc:
        raise self.retry(exc=exc, countdown=2 ** self.request.retries)
```

### 4. **Settings Configuration**

```python
# settings/third_party.py

# Code Execution Settings
CODE_EXECUTION_ENABLED = env.bool('CODE_EXECUTION_ENABLED', default=False)
SANDBOX_API_KEY = env('SANDBOX_API_KEY', default='')
CODE_EXECUTION_TIMEOUT = env.int('CODE_EXECUTION_TIMEOUT', default=30)
CODE_MEMORY_LIMIT = env.int('CODE_MEMORY_LIMIT', default=512)  # MB
CODE_CPU_LIMIT = env.float('CODE_CPU_LIMIT', default=0.5)

# Sandbox provider: 'e2b', 'docker-gvisor', 'firecracker'
SANDBOX_PROVIDER = env('SANDBOX_PROVIDER', default='e2b')
```

### 5. **Model for Execution Tracking**

```python
# apps/ai/models/code_execution.py
from django.db import models
from apps.common.behaviors import Timestampable, Authorable

class CodeExecution(Timestampable, Authorable):
    """Track all code execution attempts."""

    class Status(models.TextChoices):
        PENDING = 'pending', 'Pending'
        RUNNING = 'running', 'Running'
        SUCCESS = 'success', 'Success'
        FAILED = 'failed', 'Failed'
        TIMEOUT = 'timeout', 'Timeout'

    execution_id = models.UUIDField(unique=True, db_index=True)
    code = models.TextField()
    language = models.CharField(max_length=50)
    status = models.CharField(
        max_length=20,
        choices=Status.choices,
        default=Status.PENDING
    )

    # Results
    output = models.TextField(blank=True)
    error = models.TextField(blank=True)
    execution_time_ms = models.IntegerField(null=True)

    # Resource usage
    memory_used_mb = models.IntegerField(null=True)
    cpu_time_ms = models.IntegerField(null=True)

    # Security
    security_warnings = models.JSONField(default=list)
    validation_passed = models.BooleanField(default=False)

    class Meta:
        db_table = 'code_executions'
        indexes = [
            models.Index(fields=['author', '-created_at']),
            models.Index(fields=['status', '-created_at']),
        ]
```

### 6. **Security Checklist**

Before deploying to production:

- [ ] Enable all resource limits (CPU, memory, time)
- [ ] Implement AST validation for Python code
- [ ] Configure network isolation (no network by default)
- [ ] Set up comprehensive logging and monitoring
- [ ] Enable audit trail for all executions
- [ ] Implement rate limiting per user
- [ ] Configure alerts for suspicious activity
- [ ] Test sandbox escape scenarios
- [ ] Document incident response procedures
- [ ] Set up automated security scanning
- [ ] Review and test error handling
- [ ] Implement rollback mechanisms
- [ ] Configure compliance logging (GDPR, etc.)
- [ ] Set up regular security audits
- [ ] Test with malicious code samples

---

## Sources

This research is based on authoritative industry sources including OWASP security standards, production implementations from AWS Lambda and E2B, academic research on WebAssembly security, and best practices from major cloud providers. Key references include:

- [Secure Boundaries: Understanding LLM Sandbox Environments](https://www.sandgarden.com/learn/llm-sandbox)
- [OWASP Top 10 for Large Language Model Applications](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
- [gVisor - The Container Security Platform](https://gvisor.dev/)
- [Firecracker Lightweight Virtualization](https://aws.amazon.com/blogs/aws/firecracker-lightweight-virtualization-for-serverless-computing/)
- [WebAssembly Security Documentation](https://webassembly.org/docs/security/)
- [E2B Cloud for AI Agents](https://e2b.dev/)
- [Python Resource Limitation Guide](https://luminousmen.com/post/python-resource-limitation/)
- [Security planning for LLM-based applications - Microsoft](https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/generative-ai/mlops-in-openai/security/security-plan-llm-application)

Complete citation list available in appendix with 40+ authoritative sources.

---

## Conclusion

Safe LLM code execution requires a multi-layered security approach combining:

1. **OS-level isolation** (containers, microVMs, or WebAssembly)
2. **Resource limitations** (CPU, memory, time, network)
3. **Code validation** (AST analysis, whitelisting)
4. **Minimal permissions** (capability-based security)
5. **Comprehensive monitoring** (logging, auditing, alerting)
6. **Robust error handling** (rollback, recovery, degradation)

**Pure Python sandboxing is fundamentally insecure** and should never be relied upon for production systems.

For Django applications, the recommended approach depends on scale:
- **Small scale**: Use E2B's managed service
- **Medium scale**: Self-host with gVisor containers
- **Large scale**: Implement Firecracker microVMs with Kubernetes

Always implement defense in depth, treat LLM output as untrusted, and maintain comprehensive audit logs for security and compliance.
